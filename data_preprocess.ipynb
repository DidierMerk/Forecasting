{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f2ef7-e7a9-4a68-bb50-77625a046bd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T10:08:49.285677Z",
     "iopub.status.busy": "2024-10-21T10:08:49.284441Z",
     "iopub.status.idle": "2024-10-21T10:08:50.483482Z",
     "shell.execute_reply": "2024-10-21T10:08:50.482335Z",
     "shell.execute_reply.started": "2024-10-21T10:08:49.285610Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42767697-4b84-4263-95f0-33ba768f1e2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T10:08:50.485174Z",
     "iopub.status.busy": "2024-10-21T10:08:50.484857Z",
     "iopub.status.idle": "2024-10-21T10:08:50.490942Z",
     "shell.execute_reply": "2024-10-21T10:08:50.489831Z",
     "shell.execute_reply.started": "2024-10-21T10:08:50.485150Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load all parquet files function\n",
    "def combine_parquet_files(directory):\n",
    "    # Get all parquet files in the directory\n",
    "    parquet_files = glob.glob(os.path.join(directory, '*.parquet'))\n",
    "    \n",
    "    # Read and concatenate all parquet files\n",
    "    df_list = []\n",
    "    for file in parquet_files:\n",
    "        df = pd.read_parquet(file)\n",
    "        df_list.append(df)\n",
    "    \n",
    "    # Combine all dataframes\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2901285-cfed-428b-a931-bdd991b7a897",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T10:08:50.491710Z",
     "iopub.status.busy": "2024-10-21T10:08:50.491524Z",
     "iopub.status.idle": "2024-10-21T10:08:58.158730Z",
     "shell.execute_reply": "2024-10-21T10:08:58.158098Z",
     "shell.execute_reply.started": "2024-10-21T10:08:50.491691Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the files\n",
    "directory = 'data/data_parquet'\n",
    "result_df = combine_parquet_files(directory)\n",
    "\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796b4748-7bf8-4511-97e4-8a6ce51eb96a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T10:08:58.160317Z",
     "iopub.status.busy": "2024-10-21T10:08:58.159412Z",
     "iopub.status.idle": "2024-10-21T10:08:58.928799Z",
     "shell.execute_reply": "2024-10-21T10:08:58.928067Z",
     "shell.execute_reply.started": "2024-10-21T10:08:58.160294Z"
    }
   },
   "outputs": [],
   "source": [
    "# Some information\n",
    "individual_accounts = result_df['name'].nunique()\n",
    "ultimate_parents = result_df['ultimate_parent_id'].nunique()\n",
    "print(f\"There are {individual_accounts} individual accounts and {ultimate_parents} ultimate parents.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d40a45-031c-4b59-b913-8bb280d34506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T10:08:58.930790Z",
     "iopub.status.busy": "2024-10-21T10:08:58.930518Z",
     "iopub.status.idle": "2024-10-21T10:09:00.838507Z",
     "shell.execute_reply": "2024-10-21T10:09:00.837344Z",
     "shell.execute_reply.started": "2024-10-21T10:08:58.930767Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aggregate the timeseries by ultimate parent\n",
    "result_df['date'] = pd.to_datetime(result_df['date'])\n",
    "\n",
    "# Group by 'group_id' and 'date', then sum the 'c' values\n",
    "aggregated_df = result_df.groupby(['ultimate_parent_id', 'date'])['balance'].sum().reset_index()\n",
    "\n",
    "# If you want to sort the result\n",
    "aggregated_df = aggregated_df.sort_values(['ultimate_parent_id', 'date'])\n",
    "\n",
    "aggregated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7735e1-5a3b-4939-85e8-02ef5db03557",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T10:09:00.839731Z",
     "iopub.status.busy": "2024-10-21T10:09:00.839484Z",
     "iopub.status.idle": "2024-10-21T10:09:00.850061Z",
     "shell.execute_reply": "2024-10-21T10:09:00.848858Z",
     "shell.execute_reply.started": "2024-10-21T10:09:00.839709Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to view the timeseries\n",
    "def plot_random_timeseries_grid(df, n_series=10):\n",
    "    # Set the style for the plot\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.rcParams['font.size'] = 8\n",
    "\n",
    "    # Get unique group_ids and randomly sample n_series of them\n",
    "    unique_groups = df['ultimate_parent_id'].unique()\n",
    "    if len(unique_groups) < n_series:\n",
    "        print(f\"Warning: Only {len(unique_groups)} unique groups available. Plotting all of them.\")\n",
    "        n_series = len(unique_groups)\n",
    "    random_groups = random.sample(list(unique_groups), n_series)\n",
    "\n",
    "    # Calculate grid dimensions\n",
    "    n_cols = min(3, n_series)\n",
    "    n_rows = math.ceil(n_series / n_cols)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 3*n_rows))\n",
    "    fig.suptitle('Random Timeseries', fontsize=16, y=1.02)\n",
    "\n",
    "    # Flatten axes array for easier indexing\n",
    "    axes = axes.flatten() if n_series > 1 else [axes]\n",
    "\n",
    "    # Plot each timeseries\n",
    "    for i, group in enumerate(random_groups):\n",
    "        group_data = df[df['ultimate_parent_id'] == group].sort_values('date')\n",
    "        \n",
    "        axes[i].plot(group_data['date'], group_data['balance'], linewidth=2)\n",
    "        axes[i].set_title(f'Group ID: {group}')\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "        axes[i].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Remove unused subplots\n",
    "    for j in range(i+1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    # Improve the layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9cdfc6-9549-4f08-bc2b-93088c468d7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T10:09:00.851506Z",
     "iopub.status.busy": "2024-10-21T10:09:00.851087Z",
     "iopub.status.idle": "2024-10-21T10:09:05.399292Z",
     "shell.execute_reply": "2024-10-21T10:09:05.398114Z",
     "shell.execute_reply.started": "2024-10-21T10:09:00.851474Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_random_timeseries_grid(aggregated_df, n_series=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32022dea-78c5-454d-af59-8dd779a8ab2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T10:09:05.400621Z",
     "iopub.status.busy": "2024-10-21T10:09:05.400389Z",
     "iopub.status.idle": "2024-10-21T10:09:05.409921Z",
     "shell.execute_reply": "2024-10-21T10:09:05.408752Z",
     "shell.execute_reply.started": "2024-10-21T10:09:05.400596Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_timeseries_by_delta(df):\n",
    "    # Print the number of entries before filtering\n",
    "    print(f\"Number of entries before filtering: {len(df)}\")\n",
    "    print(f\"Number of unique groups before filtering: {df['ultimate_parent_id'].nunique()}\")\n",
    "\n",
    "    # Function to calculate the proportion of non-zero deltas and check last 30 deltas\n",
    "    def analyze_deltas(group):\n",
    "        # Sort the group by date\n",
    "        group = group.sort_values('date')\n",
    "        # Calculate deltas\n",
    "        deltas = group['balance'].diff()\n",
    "        # Calculate proportion of non-zero deltas (excluding the first NaN)\n",
    "        non_zero_delta_prop = (deltas[1:] != 0).mean()\n",
    "        # Check if last 30 deltas are all zero\n",
    "        last_30_all_zero = (deltas.tail(10) == 0).all()\n",
    "        return pd.Series({'non_zero_delta_prop': non_zero_delta_prop, 'last_30_all_zero': last_30_all_zero})\n",
    "\n",
    "    # Group by 'group_id' and apply the analysis\n",
    "    group_analysis = df.groupby('ultimate_parent_id').apply(analyze_deltas)\n",
    "\n",
    "    # Get the groups that meet both criteria:\n",
    "    # 1. More than 50% of deltas are non-zero\n",
    "    # 2. Last 30 deltas are not all zero\n",
    "    valid_groups = group_analysis[\n",
    "        (group_analysis['non_zero_delta_prop'] > 0.5) & \n",
    "        (~group_analysis['last_30_all_zero'])\n",
    "    ].index\n",
    "\n",
    "    # Filter the dataframe to keep only the valid groups\n",
    "    df_filtered = df[df['ultimate_parent_id'].isin(valid_groups)]\n",
    "\n",
    "    # Print the number of entries after filtering\n",
    "    print(f\"\\nNumber of entries after filtering: {len(df_filtered)}\")\n",
    "    print(f\"Number of unique groups after filtering: {df_filtered['ultimate_parent_id'].nunique()}\")\n",
    "\n",
    "    # Calculate and print the percentage of data removed\n",
    "    percent_removed = (1 - len(df_filtered) / len(df)) * 100\n",
    "    print(f\"\\nPercentage of data removed: {percent_removed:.2f}%\")\n",
    "\n",
    "    # Print reasons for removal\n",
    "    removed_due_to_delta = group_analysis[group_analysis['non_zero_delta_prop'] <= 0.5].index\n",
    "    removed_due_to_last_30 = group_analysis[group_analysis['last_30_all_zero']].index\n",
    "    print(f\"\\nGroups removed due to <= 50% non-zero deltas: {len(removed_due_to_delta)}\")\n",
    "    print(f\"Groups removed due to last 30 deltas being zero: {len(removed_due_to_last_30)}\")\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98133c6f-6227-43e3-bc15-a6da6d7c1bbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T10:09:05.410905Z",
     "iopub.status.busy": "2024-10-21T10:09:05.410698Z",
     "iopub.status.idle": "2024-10-21T10:09:05.916832Z",
     "shell.execute_reply": "2024-10-21T10:09:05.915780Z",
     "shell.execute_reply.started": "2024-10-21T10:09:05.410885Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filtered = filter_timeseries_by_delta(aggregated_df)\n",
    "\n",
    "plot_random_timeseries_grid(df_filtered, n_series=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc567964-2358-49b1-99d3-68c1f4727e29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T10:09:05.918138Z",
     "iopub.status.busy": "2024-10-21T10:09:05.917812Z",
     "iopub.status.idle": "2024-10-21T10:09:09.498207Z",
     "shell.execute_reply": "2024-10-21T10:09:09.497289Z",
     "shell.execute_reply.started": "2024-10-21T10:09:05.918114Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d390eb-c270-49b0-a9a7-ca2169b2d702",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T10:09:09.512493Z",
     "iopub.status.busy": "2024-10-21T10:09:09.512156Z",
     "iopub.status.idle": "2024-10-21T10:09:09.519317Z",
     "shell.execute_reply": "2024-10-21T10:09:09.518368Z",
     "shell.execute_reply.started": "2024-10-21T10:09:09.512468Z"
    }
   },
   "outputs": [],
   "source": [
    "def pivot_anonymize_and_save(df, output_file):\n",
    "    # Step 1: Create a mapping of original group_ids to anonymized ids\n",
    "    unique_groups = df['ultimate_parent_id'].unique()\n",
    "    group_mapping = {group: i for i, group in enumerate(unique_groups)}\n",
    "    \n",
    "    # Step 2: Apply the mapping to create a new anonymized group_id column\n",
    "    df['index'] = df['ultimate_parent_id'].map(group_mapping)\n",
    "    \n",
    "    # Step 3: Pivot the dataframe\n",
    "    pivoted_df = df.pivot(index='date', columns='index', values='balance')\n",
    "    \n",
    "    # Step 4: Reset the index to make 'date' a column again\n",
    "    pivoted_df.reset_index(inplace=True)\n",
    "    \n",
    "    # Step 5: Sort the dataframe by date\n",
    "    pivoted_df.sort_values('date', inplace=True)\n",
    "    \n",
    "    # Step 6: Save the pivoted and anonymized dataframe to a CSV file\n",
    "    pivoted_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Pivoted and anonymized data saved to {output_file}\")\n",
    "    print(f\"Number of unique group_ids: {len(unique_groups)}\")\n",
    "    print(f\"Shape of pivoted dataframe: {pivoted_df.shape}\")\n",
    "    \n",
    "    return pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d63ef2-74a3-49cc-ac96-455215597d68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T10:09:09.520259Z",
     "iopub.status.busy": "2024-10-21T10:09:09.520051Z",
     "iopub.status.idle": "2024-10-21T10:09:09.859105Z",
     "shell.execute_reply": "2024-10-21T10:09:09.857261Z",
     "shell.execute_reply.started": "2024-10-21T10:09:09.520238Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pivot and save the data\n",
    "pivoted_df = pivot_anonymize_and_save(df_filtered, 'data/eod_balances_2110_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c7f2a1-5160-4ca7-8f43-59e1a9b92b42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T10:09:09.866288Z",
     "iopub.status.busy": "2024-10-21T10:09:09.865475Z",
     "iopub.status.idle": "2024-10-21T10:09:09.900017Z",
     "shell.execute_reply": "2024-10-21T10:09:09.899067Z",
     "shell.execute_reply.started": "2024-10-21T10:09:09.866224Z"
    }
   },
   "outputs": [],
   "source": [
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2a07da-27cf-4978-84b5-911d7574332e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T10:09:09.900980Z",
     "iopub.status.busy": "2024-10-21T10:09:09.900778Z",
     "iopub.status.idle": "2024-10-21T10:09:09.906669Z",
     "shell.execute_reply": "2024-10-21T10:09:09.905760Z",
     "shell.execute_reply.started": "2024-10-21T10:09:09.900959Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to remove columns and create tiny test dataframe\n",
    "def remove_last_n_columns(df, n):\n",
    "    # Check if n is greater than the number of columns\n",
    "    if n >= len(df.columns):\n",
    "        raise ValueError(f\"n ({n}) must be less than the number of columns ({len(df.columns)})\")\n",
    "    \n",
    "    # Calculate the number of columns to keep\n",
    "    columns_to_keep = len(df.columns) - n\n",
    "    \n",
    "    # Create a new DataFrame with only the kept columns\n",
    "    df_trimmed = df.iloc[:, :columns_to_keep]\n",
    "    \n",
    "    print(f\"Removed last {n} columns\")\n",
    "    print(f\"Original shape: {df.shape}\")\n",
    "    print(f\"New shape: {df_trimmed.shape}\")\n",
    "    \n",
    "    return df_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e5e68f-bcab-4e3b-b4c7-8d02b2485403",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T10:09:09.907658Z",
     "iopub.status.busy": "2024-10-21T10:09:09.907443Z",
     "iopub.status.idle": "2024-10-21T10:09:09.942220Z",
     "shell.execute_reply": "2024-10-21T10:09:09.941601Z",
     "shell.execute_reply.started": "2024-10-21T10:09:09.907638Z"
    }
   },
   "outputs": [],
   "source": [
    "df_trimmed = remove_last_n_columns(pivoted_df, 252)\n",
    "\n",
    "df_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338c78a6-6ba9-4b9a-949d-0e34567534eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T10:09:09.943155Z",
     "iopub.status.busy": "2024-10-21T10:09:09.942875Z",
     "iopub.status.idle": "2024-10-21T10:09:09.971966Z",
     "shell.execute_reply": "2024-10-21T10:09:09.971277Z",
     "shell.execute_reply.started": "2024-10-21T10:09:09.943133Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the small version too\n",
    "df_trimmed.to_csv('data/eod_balances_2110_tiny.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d423ce-be23-4ff0-b57e-337a65162ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd7f8df-9a3f-4d07-8f87-28d36fe40df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAP Environment",
   "language": "python",
   "name": "dap-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
