{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18ac1deb-76f5-4ac5-aa19-fbc02c14b6c0",
   "metadata": {},
   "source": [
    "# Timeseries Forecasting (ARIMA model)\n",
    "\n",
    "## 1. Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fed1edf-90b6-45fc-9a4b-217968cd9006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T19:34:45.475760Z",
     "iopub.status.busy": "2024-10-30T19:34:45.475106Z",
     "iopub.status.idle": "2024-10-30T19:34:45.481063Z",
     "shell.execute_reply": "2024-10-30T19:34:45.479559Z",
     "shell.execute_reply.started": "2024-10-30T19:34:45.475711Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install datasetsforecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d22b76-df67-47f1-9975-c3ff312978c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T19:34:45.484637Z",
     "iopub.status.busy": "2024-10-30T19:34:45.483762Z",
     "iopub.status.idle": "2024-10-30T19:34:45.489585Z",
     "shell.execute_reply": "2024-10-30T19:34:45.488327Z",
     "shell.execute_reply.started": "2024-10-30T19:34:45.484586Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install sktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbe3e17-0e38-4cb6-882e-160dc6a99a01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T19:34:46.478529Z",
     "iopub.status.busy": "2024-10-30T19:34:46.478158Z",
     "iopub.status.idle": "2024-10-30T19:34:46.482890Z",
     "shell.execute_reply": "2024-10-30T19:34:46.481779Z",
     "shell.execute_reply.started": "2024-10-30T19:34:46.478498Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install statsforecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f773cee-505c-47e6-8749-b5e420c69877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T19:34:46.484478Z",
     "iopub.status.busy": "2024-10-30T19:34:46.484091Z",
     "iopub.status.idle": "2024-10-30T19:34:50.043974Z",
     "shell.execute_reply": "2024-10-30T19:34:50.042874Z",
     "shell.execute_reply.started": "2024-10-30T19:34:46.484451Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Some functions for plotting and stuff\n",
    "import utils as ts_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from IPython.display import Image\n",
    "import ast\n",
    "\n",
    "# Statistical models\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import MSTL, AutoARIMA\n",
    "\n",
    "# Retrieving the parameters\n",
    "from statsforecast.arima import arima_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6209e2-3591-4c56-9b01-ef071c89e8a4",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235bd5a6-69c8-4337-a6ba-b729073a92aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T19:34:50.045687Z",
     "iopub.status.busy": "2024-10-30T19:34:50.045180Z",
     "iopub.status.idle": "2024-10-30T19:34:50.155376Z",
     "shell.execute_reply": "2024-10-30T19:34:50.154531Z",
     "shell.execute_reply.started": "2024-10-30T19:34:50.045661Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Size of the data to read\n",
    "data_size = 'norm'\n",
    "\n",
    "# Date of the data to read\n",
    "data_date = '2110' # '1806' = 18th of June\n",
    "\n",
    "# Read the data (takes around 2 minutes)\n",
    "dataset = pd.read_csv(f\"~/Thesis/data/eod_balances_{data_date}_{data_size}.csv\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2500682b-d8b1-49a9-b218-3edd83b0e99c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T19:34:50.156626Z",
     "iopub.status.busy": "2024-10-30T19:34:50.156318Z",
     "iopub.status.idle": "2024-10-30T19:34:50.161264Z",
     "shell.execute_reply": "2024-10-30T19:34:50.160275Z",
     "shell.execute_reply.started": "2024-10-30T19:34:50.156599Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the timer\n",
    "timer = ts_utils.Timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546c3be9-82f7-40d2-919e-5c6302b774f8",
   "metadata": {},
   "source": [
    "### 2.1 In-sample and Out-sample split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f08a8bf-a98a-416a-b33d-699c27a838e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T19:34:50.162727Z",
     "iopub.status.busy": "2024-10-30T19:34:50.162502Z",
     "iopub.status.idle": "2024-10-30T19:34:50.170312Z",
     "shell.execute_reply": "2024-10-30T19:34:50.169059Z",
     "shell.execute_reply.started": "2024-10-30T19:34:50.162705Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate total amount of timeseries\n",
    "num_timeseries = len(dataset.columns) - 1\n",
    "\n",
    "# Specify train test split percentage\n",
    "train_test_split = 0.8\n",
    "\n",
    "# Split into train and out of sample test data\n",
    "num_out_of_sample = int(train_test_split * num_timeseries)\n",
    "\n",
    "# Create in-sample dataframe\n",
    "in_sample_data = dataset.iloc[:, : num_out_of_sample + 1] # Training and testing\n",
    "\n",
    "# Create out-sample dataframe\n",
    "n = num_timeseries-num_out_of_sample\n",
    "columns_to_keep = dataset.columns[[0]].tolist() + dataset.columns[-n:].tolist()\n",
    "out_sample_data = dataset[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f2f4e-770c-4f5c-b324-8fcdd1ab6a2c",
   "metadata": {},
   "source": [
    "## 3. In-sample Analysis\n",
    "\n",
    "### 3.1 Train/Test splitting and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5154aec-9ed0-460d-97eb-2b133221fc33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T19:34:52.477675Z",
     "iopub.status.busy": "2024-10-30T19:34:52.477134Z",
     "iopub.status.idle": "2024-10-30T19:34:52.552281Z",
     "shell.execute_reply": "2024-10-30T19:34:52.550891Z",
     "shell.execute_reply.started": "2024-10-30T19:34:52.477640Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change the data to the long format\n",
    "Y_df = in_sample_data.melt(id_vars=['date'], var_name='unique_id', value_name='y')\n",
    "Y_df = Y_df.rename(columns={'date':'ds'})\n",
    "\n",
    "# Convert date column to datetime type\n",
    "Y_df['ds'] = pd.to_datetime(Y_df['ds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40866b4-f1b1-49ac-b6e2-82fcbc515047",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T19:34:54.474474Z",
     "iopub.status.busy": "2024-10-30T19:34:54.473168Z",
     "iopub.status.idle": "2024-10-30T19:34:54.497553Z",
     "shell.execute_reply": "2024-10-30T19:34:54.495693Z",
     "shell.execute_reply.started": "2024-10-30T19:34:54.474371Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the horizon (12 months of 30 days each)\n",
    "fh = 30\n",
    "horizon = 12 * fh\n",
    "\n",
    "# Identify the unique dates in the dataset\n",
    "unique_dates = Y_df['ds'].unique()\n",
    "\n",
    "# Convert to a list and then sort the dates\n",
    "unique_dates = sorted(list(unique_dates))\n",
    "\n",
    "# Determine the cutoff date (cutoff at 12 months before the last date in the dataset)\n",
    "cutoff_date = unique_dates[-(horizon + 1)]\n",
    "\n",
    "# Training data: all data up to the cutoff date\n",
    "Y_train_df = Y_df[Y_df['ds'] <= cutoff_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f043851-ab37-4693-9f9e-d2e7f822044c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T19:34:54.502005Z",
     "iopub.status.busy": "2024-10-30T19:34:54.500900Z",
     "iopub.status.idle": "2024-10-30T19:34:54.570998Z",
     "shell.execute_reply": "2024-10-30T19:34:54.569628Z",
     "shell.execute_reply.started": "2024-10-30T19:34:54.501914Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize lists to store the input and test sets\n",
    "input_dfs = []\n",
    "test_dfs = []\n",
    "\n",
    "# Loop to create the 6 input and test sets\n",
    "for i in range(6):\n",
    "    # Determine the start date of the test period\n",
    "    test_start_date = unique_dates[-(horizon - i * 2 * fh)]\n",
    "    test_end_date = unique_dates[-(horizon - (i * 2 * fh) - fh)]\n",
    "    \n",
    "    # Input data: all data up to the start of the current test period\n",
    "    input_df = Y_df[Y_df['ds'] <= test_start_date]\n",
    "    input_dfs.append(input_df)\n",
    "    \n",
    "    # Test data: the 30-day period following the start of the test period\n",
    "    test_df = Y_df[(Y_df['ds'] > test_start_date) & (Y_df['ds'] <= test_end_date)]\n",
    "    test_dfs.append(test_df)\n",
    "\n",
    "# Define the 6 input periods\n",
    "Y_input_df_0 = input_dfs[0]\n",
    "Y_input_df_1 = input_dfs[1]\n",
    "Y_input_df_2 = input_dfs[2]\n",
    "Y_input_df_3 = input_dfs[3]\n",
    "Y_input_df_4 = input_dfs[4]\n",
    "Y_input_df_5 = input_dfs[5]\n",
    "\n",
    "# Define the 6 test periods\n",
    "Y_test_df_0 = test_dfs[0]\n",
    "Y_test_df_1 = test_dfs[1]\n",
    "Y_test_df_2 = test_dfs[2]\n",
    "Y_test_df_3 = test_dfs[3]\n",
    "Y_test_df_4 = test_dfs[4]\n",
    "Y_test_df_5 = test_dfs[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b509460-f4f4-4742-80fa-00a1c5125c2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T19:34:56.476557Z",
     "iopub.status.busy": "2024-10-30T19:34:56.476085Z",
     "iopub.status.idle": "2024-10-30T19:34:57.836796Z",
     "shell.execute_reply": "2024-10-30T19:34:57.836084Z",
     "shell.execute_reply.started": "2024-10-30T19:34:56.476523Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to plot the series and create the gif\n",
    "def create_timeseries_gif(unique_id, Y_df):\n",
    "    # Filter the data for the given unique_id\n",
    "    ts_data = Y_df[Y_df['unique_id'] == unique_id].copy()\n",
    "\n",
    "    # Sort by date\n",
    "    ts_data = ts_data.sort_values('ds')\n",
    "\n",
    "    # Last 720 points for visualization\n",
    "    ts_data = ts_data[:]\n",
    "\n",
    "    # Determine the unique dates in the dataset\n",
    "    unique_dates = sorted(list(ts_data['ds'].unique()))\n",
    "\n",
    "    # Define the major cutoff date\n",
    "    cutoff_date = unique_dates[-(horizon + 1)]\n",
    "\n",
    "    # Initialize figure with a larger size for higher quality\n",
    "    fig, ax = plt.subplots(figsize=(18, 5))  # Increased size for higher quality\n",
    "\n",
    "    # Define colors for the different regions\n",
    "    colors = {\n",
    "        'train': '#a6bddb',\n",
    "        'input': '#fd8d3c',\n",
    "        'test': '#feb24c',\n",
    "        'unused': '#ffeda0'\n",
    "    }\n",
    "\n",
    "    # Function to update the plot for each frame\n",
    "    def update(frame):\n",
    "        ax.clear()\n",
    "        ax.plot(ts_data['ds'], ts_data['y'], color='blue', linewidth=0.75)\n",
    "\n",
    "        # Highlight different regions\n",
    "        test_start_date = unique_dates[-(horizon - frame * 2 * fh)]\n",
    "        test_end_date = unique_dates[-(horizon - (frame * 2 * fh) - fh)]\n",
    "\n",
    "        # Train data fill (diagonal lines)\n",
    "        ax.fill_between(ts_data['ds'], ts_data['y'].min(), ts_data['y'].max(),\n",
    "                        where=(ts_data['ds'] <= cutoff_date), \n",
    "                        facecolor='none', edgecolor=colors['train'], hatch='//', linewidth=0, label='Train Data')\n",
    "\n",
    "        # Input data fill (from the start of the timeseries to the start of the test period)\n",
    "        ax.fill_between(ts_data['ds'], ts_data['y'].min(), ts_data['y'].max(),\n",
    "                        where=(ts_data['ds'] <= test_start_date), \n",
    "                        facecolor=colors['input'], alpha=0.15, label=f'Input Data')\n",
    "        \n",
    "        # Test data fill\n",
    "        ax.fill_between(ts_data['ds'], ts_data['y'].min(), ts_data['y'].max(),\n",
    "                        where=((ts_data['ds'] > test_start_date) & (ts_data['ds'] <= test_end_date)), \n",
    "                        facecolor=colors['test'], alpha=0.5, label=f'Test Data')\n",
    "        \n",
    "        # # Unused data fill\n",
    "        # ax.fill_between(ts_data['ds'], ts_data['y'].min(), ts_data['y'].max(),\n",
    "        #                 where=(ts_data['ds'] > test_end_date), alpha=0.35, facecolor=colors['unused'], label='Unused Data')\n",
    "\n",
    "        # Add the major cutoff vertical dotted line\n",
    "        ax.axvline(cutoff_date, color='black', linestyle='dashdot', linewidth=1)\n",
    "\n",
    "        # Add gray vertical dotted lines on each side of the test period\n",
    "        ax.axvline(test_start_date, color='gray', linestyle='--', linewidth=0.75)\n",
    "        ax.axvline(test_end_date, color='gray', linestyle='--', linewidth=0.75)\n",
    "\n",
    "        # Set plot title and labels\n",
    "        ax.set_title(f'Evaluation Visualisation - Test Period {frame+1}')\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel('Value')\n",
    "        ax.legend(loc='upper left')\n",
    "\n",
    "    # Create an animation with a slightly longer delay\n",
    "    ani = FuncAnimation(fig, update, frames=6, repeat=False)\n",
    "\n",
    "    # Save the animation as a gif with a longer frame duration\n",
    "    gif_path = f'figures/{unique_id}_timeseries.gif'\n",
    "    ani.save(gif_path, writer=PillowWriter(fps=1))  # Adjusted fps for slower animation\n",
    "\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Display the GIF in the notebook\n",
    "    return Image(gif_path)\n",
    "\n",
    "# Create the gif\n",
    "unique_id = '6'\n",
    "create_timeseries_gif(unique_id, Y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dea97d-48ac-4a7d-bbf4-554154ef8899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T19:52:42.474983Z",
     "iopub.status.busy": "2024-10-30T19:52:42.474495Z",
     "iopub.status.idle": "2024-10-30T19:52:48.410675Z",
     "shell.execute_reply": "2024-10-30T19:52:48.408698Z",
     "shell.execute_reply.started": "2024-10-30T19:52:42.474954Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_timeseries_grid(unique_id, Y_df, \n",
    "                          fontsize_config={\n",
    "                              'title': 14,\n",
    "                              'axis_label': 12,\n",
    "                              'ticks': 10,\n",
    "                              'legend': 12\n",
    "                          },\n",
    "                          spacing_config={\n",
    "                              'vertical': 0.3,     # Space between rows\n",
    "                              'horizontal': 0.2,   # Space between columns\n",
    "                              'top': 0.95,         # Top margin for legend\n",
    "                              'title_pad': 20,     # Space between title and plot\n",
    "                              'xlabel_pad': 10,    # Space between xlabel and plot\n",
    "                              'ylabel_pad': 10     # Space between ylabel and plot\n",
    "                          }):\n",
    "    # Filter the data for the given unique_id\n",
    "    ts_data = Y_df[Y_df['unique_id'] == unique_id].copy()\n",
    "\n",
    "    # Sort by date\n",
    "    ts_data = ts_data.sort_values('ds')\n",
    "\n",
    "    # Determine the unique dates in the dataset\n",
    "    unique_dates = sorted(list(ts_data['ds'].unique()))\n",
    "\n",
    "    # Define the major cutoff date\n",
    "    cutoff_date = unique_dates[-(horizon + 1)]\n",
    "\n",
    "    # Create figure and gridspec with specified spacing\n",
    "    fig = plt.figure(figsize=(30, 12))\n",
    "    gs = fig.add_gridspec(3, 2, \n",
    "                         hspace=spacing_config['vertical'],\n",
    "                         wspace=spacing_config['horizontal'])\n",
    "    axes = gs.subplots()\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Define colors for the different regions\n",
    "    colors = {\n",
    "        'train': '#a6bddb',\n",
    "        'input': '#fd8d3c',\n",
    "        'test': '#feb24c',\n",
    "        'unused': '#ffeda0'\n",
    "    }\n",
    "\n",
    "    # Create dummy plot for legend\n",
    "    legend_elements = [\n",
    "        plt.fill_between([], [], facecolor='none', edgecolor=colors['train'], \n",
    "                        hatch='//', label='Train Data'),\n",
    "        plt.fill_between([], [], facecolor=colors['input'], alpha=0.15, \n",
    "                        label='Input Data'),\n",
    "        plt.fill_between([], [], facecolor=colors['test'], alpha=0.5, \n",
    "                        label='Test Data')\n",
    "    ]\n",
    "    \n",
    "    # Add legend above all subplots\n",
    "    fig.legend(handles=legend_elements, \n",
    "              loc='upper center', \n",
    "              bbox_to_anchor=(0.5, spacing_config['top']),\n",
    "              ncol=3,  # Arrange legend items horizontally\n",
    "              fontsize=fontsize_config['legend'],\n",
    "              frameon=True,\n",
    "              edgecolor='black')\n",
    "\n",
    "    # Create each subplot\n",
    "    for frame, ax in enumerate(axes):\n",
    "        ax.plot(ts_data['ds'], ts_data['y'], color='blue', linewidth=0.75)\n",
    "\n",
    "        # Calculate test period dates\n",
    "        test_start_date = unique_dates[-(horizon - frame * 2 * fh)]\n",
    "        test_end_date = unique_dates[-(horizon - (frame * 2 * fh) - fh)]\n",
    "\n",
    "        # Train data fill (diagonal lines)\n",
    "        ax.fill_between(ts_data['ds'], ts_data['y'].min(), ts_data['y'].max(),\n",
    "                       where=(ts_data['ds'] <= cutoff_date), \n",
    "                       facecolor='none', edgecolor=colors['train'], hatch='//', linewidth=0)\n",
    "\n",
    "        # Input data fill\n",
    "        ax.fill_between(ts_data['ds'], ts_data['y'].min(), ts_data['y'].max(),\n",
    "                       where=(ts_data['ds'] <= test_start_date), \n",
    "                       facecolor=colors['input'], alpha=0.15)\n",
    "        \n",
    "        # Test data fill\n",
    "        ax.fill_between(ts_data['ds'], ts_data['y'].min(), ts_data['y'].max(),\n",
    "                       where=((ts_data['ds'] > test_start_date) & (ts_data['ds'] <= test_end_date)), \n",
    "                       facecolor=colors['test'], alpha=0.5)\n",
    "\n",
    "        # Add the major cutoff vertical dotted line\n",
    "        ax.axvline(cutoff_date, color='black', linestyle='dashdot', linewidth=1)\n",
    "\n",
    "        # Add gray vertical dotted lines on each side of the test period\n",
    "        ax.axvline(test_start_date, color='gray', linestyle='--', linewidth=0.75)\n",
    "        ax.axvline(test_end_date, color='gray', linestyle='--', linewidth=0.75)\n",
    "\n",
    "        # Set subplot title with configured padding\n",
    "        ax.set_title(f'Test Period {frame+1}', \n",
    "                    fontsize=fontsize_config['title'],\n",
    "                    pad=spacing_config['title_pad'])\n",
    "        \n",
    "        # Only show x-axis labels and ticks for bottom plots (indices 4 and 5)\n",
    "        if frame in [4, 5]:\n",
    "            ax.set_xlabel('Date', \n",
    "                         fontsize=fontsize_config['axis_label'],\n",
    "                         labelpad=spacing_config['xlabel_pad'])\n",
    "            ax.tick_params(axis='x', labelsize=fontsize_config['ticks'])\n",
    "        else:\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_xlabel('')\n",
    "        \n",
    "        # Only show y-axis labels and ticks for left-most plots (indices 0, 2, 4)\n",
    "        if frame % 2 == 0: \n",
    "            ax.set_ylabel('Value', \n",
    "                         fontsize=fontsize_config['axis_label'],\n",
    "                         labelpad=spacing_config['ylabel_pad'])\n",
    "            ax.tick_params(axis='y', labelsize=fontsize_config['ticks'])\n",
    "        else:\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_ylabel('')\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(f'figures/{unique_id}_timeseries_grid.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Display the image\n",
    "    return Image(f'figures/{unique_id}_timeseries_grid.png')\n",
    "\n",
    "# Example usage with default settings\n",
    "unique_id = '20'\n",
    "create_timeseries_grid(unique_id, Y_df)\n",
    "\n",
    "# Example usage with custom settings\n",
    "custom_config = {\n",
    "    'fontsize_config': {\n",
    "        'title': 22,\n",
    "        'axis_label': 18,\n",
    "        'ticks': 12,\n",
    "        'legend': 18\n",
    "    },\n",
    "    'spacing_config': {\n",
    "        'vertical': 0.28,\n",
    "        'horizontal': 0.05,\n",
    "        'top': 0.97,\n",
    "        'title_pad': 15,\n",
    "        'xlabel_pad': 15,\n",
    "        'ylabel_pad': 10\n",
    "    }\n",
    "}\n",
    "create_timeseries_grid(unique_id, Y_df, **custom_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c18daa1-c633-4422-b005-5ab38efc7dc6",
   "metadata": {},
   "source": [
    "### 3.2 Training models using correct seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bad2a9a-d707-4dc1-b759-5f6c2efeffa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T12:18:28.689491Z",
     "iopub.status.busy": "2024-10-30T12:18:28.688550Z",
     "iopub.status.idle": "2024-10-30T12:18:28.710109Z",
     "shell.execute_reply": "2024-10-30T12:18:28.708924Z",
     "shell.execute_reply.started": "2024-10-30T12:18:28.689384Z"
    }
   },
   "outputs": [],
   "source": [
    "def forecast_mstl_autoarima(Y_input_df, seasonalities_df, h=30, levels=[60, 70, 80, 90], freq='D', n_jobs=5):\n",
    "    \"\"\"\n",
    "    Forecast time series data using MSTL + AutoARIMA model with specified seasonalities.\n",
    "\n",
    "    Parameters:\n",
    "    - Y_input_df (pd.DataFrame): Input DataFrame containing 'unique_id', 'ds', 'y' columns.\n",
    "    - seasonalities_df (pd.DataFrame): DataFrame containing 'unique_id' and 'best_fit' columns.\n",
    "    - h (int): Forecast horizon.\n",
    "    - levels (list of int): Confidence levels for prediction intervals.\n",
    "    - freq (str): Frequency of the time series data.\n",
    "    - n_jobs (int): Number of parallel jobs to run.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Forecasts with prediction intervals, containing 'unique_id', 'ds', 'ARIMA', and interval columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Process 'best_fit' column to get 'season_length_list'\n",
    "    def parse_season_length(s):\n",
    "        return ast.literal_eval(s)\n",
    "\n",
    "    seasonalities_df = seasonalities_df.copy()\n",
    "    seasonalities_df['season_length_list'] = seasonalities_df['best_fit'].apply(parse_season_length)\n",
    "    seasonalities_df['unique_id'] = seasonalities_df['unique_id'].astype(str)\n",
    "\n",
    "    # Step 2: Merge seasonality info with input data\n",
    "    Y_input_df = Y_input_df.copy()\n",
    "    Y_input_df['unique_id'] = Y_input_df['unique_id'].astype(str)\n",
    "    Y_input_df = Y_input_df.merge(\n",
    "        seasonalities_df[['unique_id', 'season_length_list']],\n",
    "        on='unique_id',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Check for any missing seasonality information\n",
    "    missing_seasonalities = Y_input_df[Y_input_df['season_length_list'].isnull()]['unique_id'].unique()\n",
    "    if len(missing_seasonalities) > 0:\n",
    "        print(f\"Warning: Missing seasonality information for unique_ids: {missing_seasonalities}\")\n",
    "        # Drop these time series\n",
    "        Y_input_df = Y_input_df.dropna(subset=['season_length_list'])\n",
    "\n",
    "    # Step 3: Group data by season_length_tuple\n",
    "    Y_input_df['season_length_tuple'] = Y_input_df['season_length_list'].apply(tuple)\n",
    "    grouped = Y_input_df.groupby('season_length_tuple')\n",
    "\n",
    "    forecast_dfs = []\n",
    "\n",
    "    # Iterate over each group and perform forecasting\n",
    "    for season_length_tuple, group_df in grouped:\n",
    "        season_length_list = list(season_length_tuple)\n",
    "        num_series = group_df['unique_id'].nunique()\n",
    "\n",
    "        print(f\"Forecasting {num_series} series with seasonality {season_length_list}...\")\n",
    "\n",
    "        # Extract necessary columns\n",
    "        data = group_df[['unique_id', 'ds', 'y']].copy()\n",
    "\n",
    "        # Handle empty season_length_list\n",
    "        if season_length_list:\n",
    "            # Non-empty seasonality\n",
    "            mstl_model = [MSTL(\n",
    "                season_length=season_length_list,\n",
    "                trend_forecaster=AutoARIMA(max_p=4, max_q=4)\n",
    "            )]\n",
    "        else:\n",
    "            print(f\"Note: We found seasonality of [], we skip the MSTL model here.\")\n",
    "\n",
    "        if season_length_list:\n",
    "            # Initialize StatsForecast\n",
    "            stats_forecast = StatsForecast(models=mstl_model, freq=freq, n_jobs=n_jobs)\n",
    "    \n",
    "            # Perform forecast with specified confidence levels\n",
    "            preds = stats_forecast.forecast(df=data, h=h, level=levels)\n",
    "    \n",
    "            # Rename forecast columns\n",
    "            preds = preds.rename(columns={'MSTL': 'ARIMA'})\n",
    "    \n",
    "            # Rename confidence interval columns\n",
    "            for level in levels:\n",
    "                lower_col = f'MSTL-lo-{level}'\n",
    "                upper_col = f'MSTL-hi-{level}'\n",
    "    \n",
    "                # Compute the tail percentage\n",
    "                tail = 100 - level\n",
    "    \n",
    "                preds = preds.rename(columns={\n",
    "                    lower_col: f'ARIMA-lo-{tail}',\n",
    "                    upper_col: f'ARIMA-hi-{level}'\n",
    "                })\n",
    "        else:\n",
    "            # Initialize StatsForecast\n",
    "            stats_forecast = StatsForecast(models=[AutoARIMA(max_p=4, max_q=4)], n_jobs=n_jobs, freq=freq)\n",
    "    \n",
    "            # Perform forecast with specified confidence levels\n",
    "            preds = stats_forecast.forecast(df=data, h=h, level=levels)\n",
    "    \n",
    "            # Rename forecast columns\n",
    "            preds = preds.rename(columns={'AutoARIMA': 'ARIMA'})\n",
    "    \n",
    "            # Rename confidence interval columns\n",
    "            for level in levels:\n",
    "                lower_col = f'AutoARIMA-lo-{level}'\n",
    "                upper_col = f'AutoARIMA-hi-{level}'\n",
    "    \n",
    "                # Compute the tail percentage\n",
    "                tail = 100 - level\n",
    "    \n",
    "                preds = preds.rename(columns={\n",
    "                    lower_col: f'ARIMA-lo-{tail}',\n",
    "                    upper_col: f'ARIMA-hi-{level}'\n",
    "                }) \n",
    "\n",
    "        # Append forecasts to the list\n",
    "        forecast_dfs.append(preds)\n",
    "\n",
    "    # Combine all forecasts into a single DataFrame\n",
    "    arima_model_insample_preds = pd.concat(forecast_dfs).reset_index(drop=False)\n",
    "\n",
    "    # Keep only necessary columns\n",
    "    cols_to_keep = ['unique_id', 'ds', 'ARIMA'] + [col for col in arima_model_insample_preds.columns if col.startswith('ARIMA-lo-') or col.startswith('ARIMA-hi-')]\n",
    "    arima_model_insample_preds = arima_model_insample_preds[cols_to_keep]\n",
    "\n",
    "    print(\"Forecasting completed.\")\n",
    "\n",
    "    return arima_model_insample_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855f1039-9d91-4866-8e54-0d8dcfca1381",
   "metadata": {},
   "source": [
    "## 4. Insample predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81838383-18fc-49b1-a94a-55efd247f330",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T12:19:40.173444Z",
     "iopub.status.busy": "2024-10-30T12:19:40.172303Z",
     "iopub.status.idle": "2024-10-30T12:19:40.187160Z",
     "shell.execute_reply": "2024-10-30T12:19:40.185967Z",
     "shell.execute_reply.started": "2024-10-30T12:19:40.173323Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set our forecasting horizon\n",
    "h = 30\n",
    "\n",
    "# Set our confidence levels\n",
    "levels = [60, 70, 80, 90]\n",
    "\n",
    "# Read the seasonalities that we got from seasonality_detection.ipynb\n",
    "seasonalities = pd.read_csv(f\"~/Thesis/models/best_fits_{data_date}_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83e810b-3aea-4c0f-930e-0aa3ed442ba7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T12:19:41.178249Z",
     "iopub.status.busy": "2024-10-30T12:19:41.177497Z",
     "iopub.status.idle": "2024-10-30T12:23:04.086515Z",
     "shell.execute_reply": "2024-10-30T12:23:04.085380Z",
     "shell.execute_reply.started": "2024-10-30T12:19:41.178176Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict the first period\n",
    "arima_model_insample_preds_0 = forecast_mstl_autoarima(Y_input_df=Y_input_df_0, seasonalities_df=seasonalities)\n",
    "\n",
    "# Save the prediction\n",
    "arima_model_insample_preds_0.to_csv(f'~/Thesis/predictions/ARIMA/insample/period01/model_preds_{data_date}_{data_size}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f22cc7-cfe7-4deb-b725-d1a7584ba851",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T12:23:04.088256Z",
     "iopub.status.busy": "2024-10-30T12:23:04.088019Z",
     "iopub.status.idle": "2024-10-30T12:29:05.002203Z",
     "shell.execute_reply": "2024-10-30T12:29:05.001135Z",
     "shell.execute_reply.started": "2024-10-30T12:23:04.088231Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict the second period\n",
    "arima_model_insample_preds_1 = forecast_mstl_autoarima(Y_input_df=Y_input_df_1, seasonalities_df=seasonalities)\n",
    "\n",
    "# Save the prediction\n",
    "arima_model_insample_preds_1.to_csv(f'~/Thesis/predictions/ARIMA/insample/period02/model_preds_{data_date}_{data_size}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a50ccb1-e1ef-4172-93f7-8f888c956ab4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T12:29:05.003362Z",
     "iopub.status.busy": "2024-10-30T12:29:05.003121Z",
     "iopub.status.idle": "2024-10-30T12:34:20.658295Z",
     "shell.execute_reply": "2024-10-30T12:34:20.656985Z",
     "shell.execute_reply.started": "2024-10-30T12:29:05.003337Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict the third period\n",
    "arima_model_insample_preds_2 = forecast_mstl_autoarima(Y_input_df=Y_input_df_2, seasonalities_df=seasonalities)\n",
    "\n",
    "# Save the prediction\n",
    "arima_model_insample_preds_2.to_csv(f'~/Thesis/predictions/ARIMA/insample/period03/model_preds_{data_date}_{data_size}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a3d143-6df3-42fc-b0e3-c5a29e283ef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T12:34:20.659843Z",
     "iopub.status.busy": "2024-10-30T12:34:20.659582Z",
     "iopub.status.idle": "2024-10-30T12:40:10.798466Z",
     "shell.execute_reply": "2024-10-30T12:40:10.796500Z",
     "shell.execute_reply.started": "2024-10-30T12:34:20.659816Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict the fourth period\n",
    "arima_model_insample_preds_3 = forecast_mstl_autoarima(Y_input_df=Y_input_df_3, seasonalities_df=seasonalities)\n",
    "\n",
    "# Save the prediction\n",
    "arima_model_insample_preds_3.to_csv(f'~/Thesis/predictions/ARIMA/insample/period04/model_preds_{data_date}_{data_size}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54b1a2c-db14-4388-bb30-efcfd7a2bcfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T12:40:10.802259Z",
     "iopub.status.busy": "2024-10-30T12:40:10.801716Z",
     "iopub.status.idle": "2024-10-30T12:43:18.795701Z",
     "shell.execute_reply": "2024-10-30T12:43:18.794545Z",
     "shell.execute_reply.started": "2024-10-30T12:40:10.802214Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict the fifth period\n",
    "arima_model_insample_preds_4 = forecast_mstl_autoarima(Y_input_df=Y_input_df_4, seasonalities_df=seasonalities)\n",
    "\n",
    "# Save the prediction\n",
    "arima_model_insample_preds_4.to_csv(f'~/Thesis/predictions/ARIMA/insample/period05/model_preds_{data_date}_{data_size}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2199c6-ab21-403d-bd64-a6cc48915b9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T12:43:18.796884Z",
     "iopub.status.busy": "2024-10-30T12:43:18.796650Z",
     "iopub.status.idle": "2024-10-30T12:46:29.927383Z",
     "shell.execute_reply": "2024-10-30T12:46:29.926013Z",
     "shell.execute_reply.started": "2024-10-30T12:43:18.796859Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict the sixth period\n",
    "arima_model_insample_preds_5 = forecast_mstl_autoarima(Y_input_df=Y_input_df_5, seasonalities_df=seasonalities)\n",
    "\n",
    "# Save the prediction\n",
    "arima_model_insample_preds_5.to_csv(f'~/Thesis/predictions/ARIMA/insample/period06/model_preds_{data_date}_{data_size}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b73b37-4d9a-4d6a-bf6d-76fdce6f67f3",
   "metadata": {},
   "source": [
    "## 5. Out-sample predictions\n",
    "\n",
    "### 5.1 Data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1d3024-a6be-4cdc-bedb-b85cc255223a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T12:46:29.929431Z",
     "iopub.status.busy": "2024-10-30T12:46:29.928864Z",
     "iopub.status.idle": "2024-10-30T12:46:29.972458Z",
     "shell.execute_reply": "2024-10-30T12:46:29.971454Z",
     "shell.execute_reply.started": "2024-10-30T12:46:29.929374Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change the data to the long format\n",
    "Y_df = out_sample_data.melt(id_vars=['date'], var_name='unique_id', value_name='y')\n",
    "Y_df = Y_df.rename(columns={'date':'ds'})\n",
    "\n",
    "# Convert date column to datetime type\n",
    "Y_df['ds'] = pd.to_datetime(Y_df['ds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc1f8ed-a9e0-4aef-9da4-783f3cac9692",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T12:46:29.974136Z",
     "iopub.status.busy": "2024-10-30T12:46:29.973617Z",
     "iopub.status.idle": "2024-10-30T12:46:29.988901Z",
     "shell.execute_reply": "2024-10-30T12:46:29.987248Z",
     "shell.execute_reply.started": "2024-10-30T12:46:29.974095Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the horizon (12 months of 30 days each)\n",
    "fh = 30\n",
    "horizon = 12 * fh\n",
    "\n",
    "# Identify the unique dates in the dataset\n",
    "unique_dates = Y_df['ds'].unique()\n",
    "\n",
    "# Convert to a list and then sort the dates\n",
    "unique_dates = sorted(list(unique_dates))\n",
    "\n",
    "# Determine the cutoff date (cutoff at 12 months before the last date in the dataset)\n",
    "cutoff_date = unique_dates[-(horizon + 1)]\n",
    "\n",
    "# Training data: all data up to the cutoff date\n",
    "Y_train_df = Y_df[Y_df['ds'] <= cutoff_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fd94b0-0099-4eb7-b72f-60702b1d030c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T12:46:29.990885Z",
     "iopub.status.busy": "2024-10-30T12:46:29.990324Z",
     "iopub.status.idle": "2024-10-30T12:46:30.033816Z",
     "shell.execute_reply": "2024-10-30T12:46:30.032375Z",
     "shell.execute_reply.started": "2024-10-30T12:46:29.990845Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize lists to store the input and test sets\n",
    "input_dfs = []\n",
    "test_dfs = []\n",
    "\n",
    "# Loop to create the 6 input and test sets\n",
    "for i in range(6):\n",
    "    # Determine the start date of the test period\n",
    "    test_start_date = unique_dates[-(horizon - i * 2 * fh)]\n",
    "    test_end_date = unique_dates[-(horizon - (i * 2 * fh) - fh)]\n",
    "    \n",
    "    # Input data: all data up to the start of the current test period\n",
    "    input_df = Y_df[Y_df['ds'] <= test_start_date]\n",
    "    input_dfs.append(input_df)\n",
    "    \n",
    "    # Test data: the 30-day period following the start of the test period\n",
    "    test_df = Y_df[(Y_df['ds'] > test_start_date) & (Y_df['ds'] <= test_end_date)]\n",
    "    test_dfs.append(test_df)\n",
    "\n",
    "# Define the 6 input periods\n",
    "Y_input_df_0 = input_dfs[0]\n",
    "Y_input_df_1 = input_dfs[1]\n",
    "Y_input_df_2 = input_dfs[2]\n",
    "Y_input_df_3 = input_dfs[3]\n",
    "Y_input_df_4 = input_dfs[4]\n",
    "Y_input_df_5 = input_dfs[5]\n",
    "\n",
    "# Define the 6 test periods\n",
    "Y_test_df_0 = test_dfs[0]\n",
    "Y_test_df_1 = test_dfs[1]\n",
    "Y_test_df_2 = test_dfs[2]\n",
    "Y_test_df_3 = test_dfs[3]\n",
    "Y_test_df_4 = test_dfs[4]\n",
    "Y_test_df_5 = test_dfs[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a148b2c4-b7c6-4682-8520-bc739b2b2af9",
   "metadata": {},
   "source": [
    "### 5.2 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be809e7c-be45-4465-b180-b82b1d6aa749",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T12:49:08.168536Z",
     "iopub.status.busy": "2024-10-30T12:49:08.168029Z",
     "iopub.status.idle": "2024-10-30T12:49:08.177086Z",
     "shell.execute_reply": "2024-10-30T12:49:08.176302Z",
     "shell.execute_reply.started": "2024-10-30T12:49:08.168488Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set our forecasting horizon\n",
    "h = 30\n",
    "\n",
    "# Set our confidence levels\n",
    "levels = [60, 70, 80, 90]\n",
    "\n",
    "# Read the seasonalities that we got from seasonality_detection.ipynb\n",
    "seasonalities = pd.read_csv(f\"~/Thesis/models/best_fits_{data_date}_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1997ee1c-a8f4-4380-b4f0-92de11501247",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T12:49:08.580549Z",
     "iopub.status.busy": "2024-10-30T12:49:08.579648Z",
     "iopub.status.idle": "2024-10-30T12:50:23.383550Z",
     "shell.execute_reply": "2024-10-30T12:50:23.382186Z",
     "shell.execute_reply.started": "2024-10-30T12:49:08.580483Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict the first period\n",
    "arima_model_outsample_preds_0 = forecast_mstl_autoarima(Y_input_df=Y_input_df_0, seasonalities_df=seasonalities)\n",
    "\n",
    "# Save the prediction\n",
    "arima_model_outsample_preds_0.to_csv(f'~/Thesis/predictions/ARIMA/outsample/period01/model_preds_{data_date}_{data_size}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cab1d4-06fd-46d1-b338-b26f5b070e2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T12:50:23.385811Z",
     "iopub.status.busy": "2024-10-30T12:50:23.385370Z",
     "iopub.status.idle": "2024-10-30T12:50:40.054641Z",
     "shell.execute_reply": "2024-10-30T12:50:40.053442Z",
     "shell.execute_reply.started": "2024-10-30T12:50:23.385781Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict the second period\n",
    "arima_model_outsample_preds_1 = forecast_mstl_autoarima(Y_input_df=Y_input_df_1, seasonalities_df=seasonalities)\n",
    "\n",
    "# Save the prediction\n",
    "arima_model_outsample_preds_1.to_csv(f'~/Thesis/predictions/ARIMA/outsample/period02/model_preds_{data_date}_{data_size}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c77daa1-ae43-4de7-8efe-f839fad450f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T12:50:40.056101Z",
     "iopub.status.busy": "2024-10-30T12:50:40.055849Z",
     "iopub.status.idle": "2024-10-30T12:50:58.969504Z",
     "shell.execute_reply": "2024-10-30T12:50:58.968045Z",
     "shell.execute_reply.started": "2024-10-30T12:50:40.056075Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict the third period\n",
    "arima_model_outsample_preds_2 = forecast_mstl_autoarima(Y_input_df=Y_input_df_2, seasonalities_df=seasonalities)\n",
    "\n",
    "# Save the prediction\n",
    "arima_model_outsample_preds_2.to_csv(f'~/Thesis/predictions/ARIMA/outsample/period03/model_preds_{data_date}_{data_size}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5674de4c-5483-4161-9861-702108a5622c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T12:50:58.972723Z",
     "iopub.status.busy": "2024-10-30T12:50:58.972143Z",
     "iopub.status.idle": "2024-10-30T12:51:17.186250Z",
     "shell.execute_reply": "2024-10-30T12:51:17.184797Z",
     "shell.execute_reply.started": "2024-10-30T12:50:58.972694Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict the fourth period\n",
    "arima_model_outsample_preds_3 = forecast_mstl_autoarima(Y_input_df=Y_input_df_3, seasonalities_df=seasonalities)\n",
    "\n",
    "# Save the prediction\n",
    "arima_model_outsample_preds_3.to_csv(f'~/Thesis/predictions/ARIMA/outsample/period04/model_preds_{data_date}_{data_size}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4699a1e8-c9c8-4c84-a62b-90407319fe2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T12:51:17.188138Z",
     "iopub.status.busy": "2024-10-30T12:51:17.187652Z",
     "iopub.status.idle": "2024-10-30T12:51:36.112822Z",
     "shell.execute_reply": "2024-10-30T12:51:36.111487Z",
     "shell.execute_reply.started": "2024-10-30T12:51:17.188108Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict the fifth period\n",
    "arima_model_outsample_preds_4 = forecast_mstl_autoarima(Y_input_df=Y_input_df_4, seasonalities_df=seasonalities)\n",
    "\n",
    "# Save the prediction\n",
    "arima_model_outsample_preds_4.to_csv(f'~/Thesis/predictions/ARIMA/outsample/period05/model_preds_{data_date}_{data_size}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ea2e68-6208-4d0c-aa0b-70990774bc8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T12:51:36.114807Z",
     "iopub.status.busy": "2024-10-30T12:51:36.114238Z",
     "iopub.status.idle": "2024-10-30T12:51:54.938338Z",
     "shell.execute_reply": "2024-10-30T12:51:54.937362Z",
     "shell.execute_reply.started": "2024-10-30T12:51:36.114767Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict the sixth period\n",
    "arima_model_outsample_preds_5 = forecast_mstl_autoarima(Y_input_df=Y_input_df_5, seasonalities_df=seasonalities)\n",
    "\n",
    "# Save the prediction\n",
    "arima_model_outsample_preds_5.to_csv(f'~/Thesis/predictions/ARIMA/outsample/period06/model_preds_{data_date}_{data_size}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19655d9-e757-4f25-a5ff-33c68673cc28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a6b3d8-5da8-4d80-82f8-3df942908374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAP Environment",
   "language": "python",
   "name": "dap-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
